---
title: "TidyTemplate"
date: 2021-06-15
output: html_output
---

# TidyTuesday

Join the R4DS Online Learning Community in the weekly #TidyTuesday event!
Every week we post a raw dataset, a chart or article related to that dataset, and ask you to explore the data.
While the dataset will be “tamed”, it will not always be tidy! As such you might need to apply various R for Data Science techniques to wrangle the data into a true tidy format.
The goal of TidyTuesday is to apply your R skills, get feedback, explore other’s work, and connect with the greater #RStats community!
As such we encourage everyone of all skills to participate!

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(scales)
library(tidytuesdayR)
library(DataExplorer)
theme_set(theme_light())
doParallel::registerDoParallel(cores = 8)
```

# Load the weekly Data

Download the weekly data and make available in the `tt` object.

```{r Load}

tt <- tt_load("2021-06-15")

```


# Readme

Take a look at the readme for the weekly data to get insight on the dataset.
This includes a data dictionary, source, and a link to an article on the data.

```{r Readme, eval = interactive()}

tweets <- tt$tweets %>% 
    filter(!is.na(content),
           !is.na(retweet_count),
           !is.na(followers),
           !is.na(quote_count),
           !is.na(like_count),
           !is.na(username))
```

## EDA

```{r}
tweets %>% 
    skimr::skim()
```

```{r}
tweets %>% 
    plot_intro()
```

```{r}
tweets %>% 
    plot_missing()
```

## Which user tweeted the most?

```{r}
tweets %>% 
    count(username, sort = TRUE) %>% 
    slice_max(n, n = 10) %>% 
    mutate(username = fct_reorder(username, n)) %>%
    ggplot(aes(n, username)) +
    geom_col() +
    geom_text(aes(label = n), hjust = -0.1) +
    labs(x = "# of tweets",
         y = "",
         title = "Top 10 most tweeted users")
```

## Top users' stats by arranged by median followers
```{r}
tweets %>% 
    group_by(username) %>% 
    summarize(median_retweet = median(retweet_count),
              median_like = median(like_count),
              median_quote = median(quote_count),
              median_followers = median(followers)) %>% 
    arrange(desc(median_followers))
```


## Top users' stats by arranged by median retweet
```{r}
tweets %>% 
    group_by(username) %>% 
    summarize(median_retweet = median(retweet_count),
              median_like = median(like_count),
              median_quote = median(quote_count),
              median_followers = median(followers)) %>% 
    arrange(desc(median_retweet))
```

## Top users' stats by arranged by median like
```{r}
tweets %>% 
    group_by(username) %>% 
    summarize(median_retweet = median(retweet_count),
              median_like = median(like_count),
              median_quote = median(quote_count),
              median_followers = median(followers)) %>% 
    arrange(desc(median_like))
```

## Top users' stats by arranged by median quote
```{r}
tweets %>% 
    group_by(username) %>% 
    summarize(median_retweet = median(retweet_count),
              median_like = median(like_count),
              median_quote = median(quote_count),
              median_followers = median(followers)) %>% 
    arrange(desc(median_quote))
```

- User with the highest median retweet count also has the highest median like and median quote,
whose username is ijeamaka_a.

## Who and which tweet has the highest retweet

```{r}
tweets %>% 
    slice_max(retweet_count, n = 1) %>% 
    select(retweet_count, content, username) 
```

## Who and which tweet has the highest like

```{r}
tweets %>% 
    slice_max(like_count, n = 1) %>% 
    select(like_count, content, username) 
```

## Who and which tweet has the highest quote

```{r}
tweets %>% 
    slice_max(quote_count, n = 1) %>% 
    select(quote_count, content, username)
```

- User **CharlieEatonPhD** has the highest retweet, like, and quote count.

## Question: What factors influence the retweet count?
### Does the user matter?

```{r}
tweets %>% 
    filter(!is.na(username)) %>% 
    mutate(username = fct_lump(username, n = 19),
           username = fct_reorder(username, retweet_count)) %>% 
    ggplot(aes(retweet_count + 1, username)) +
    geom_boxplot(aes(fill = username), alpha = 0.5)+
    scale_x_log10() +
    labs(x = "Retweet count (logged)",
         y = "",
         title = "Retweet count by most prevalent users") +
    theme(legend.position = "none")
```
- It seems that retweet count is associated with different users

### How about like and quote counts as well as followers and locations in terms of longitude and latitude

```{r}
tweets %>% 
    na.omit() %>% 
    plot_correlation(type = "continuous")
```
- It is clear that like and quote counts are extremely strong predictors of retweet count, while the variable `followers` has a positively weak correlation with retweet count. The locations seem not to matter much given the correlations for longitude and latitude with retweet count are close to 0.

### Visualize the relationship between retweet count and location

```{r}
library(leaflet)

pal <- colorFactor(palette = "RdBu",
                    domain = tweets$retweet_dummy)
tweets_map <- tweets %>% 
    mutate(popup_label = paste(paste0("<b>Location: ", "</b>",
                                      location),
                               paste0("<b>Retweet Count: ", "</b>",
                                      retweet_count),
                               sep = "<br/>"),
           retweet_dummy = if_else(retweet_count > 10, "High", "Low")) %>% 
    na.omit()

leaflet() %>% 
    addProviderTiles("Stamen.TonerLite") %>% 
    addCircleMarkers(data = tweets_map,
                     radius = 10,
                     stroke = FALSE,
                     fillOpacity = 0.7,
                     popup = ~popup_label,
                     fillColor = ~pal(retweet_dummy)) %>% 
    addLegend(data = tweets_map,
              position = "topright",
              values = ~retweet_dummy,
              title = "Retweet Count",
              pal = pal)
```

### Does datetime matter?

```{r}
# Look at the retweet count by each day
library(lubridate)
tweets %>% 
    mutate(date = date(datetime)) %>% 
    group_by(date) %>% 
    summarize(retweet_day = median(retweet_count)) %>% 
    ungroup() %>% 
    ggplot(aes(date, retweet_day)) +
    geom_line() +
    geom_smooth(method = "lm") +
    labs(x = "Date",
         y = "# of retweets (median)",
         title = "Median # of retweets by day",
         subtitle = "Feb, 2021 - May, 2021")
```

- It does not seem to have a linear relationship between the time of the tweets and retweet count.

```{r}
# Look at the retweet count by each week
tweets %>% 
    mutate(week = week(datetime)) %>% 
    group_by(week) %>% 
    summarize(retweet_week = median(retweet_count)) %>% 
    ungroup() %>% 
    ggplot(aes(week, retweet_week)) +
    geom_line() +
    geom_smooth(method = "lm") +
    labs(x = "Week",
         y = "# of retweets (median)",
         title = "Median # of retweets by week",
         subtitle = "Feb, 2021 - May, 2021")
```

- A negative association seems to exist when we organize the `datetime` by week. The median of retweet dropped in recently weeks from about 1.3 per week to less than 1 per week.


## Model
### Train, test, and validation sets

```{r}
library(tidymodels)
set.seed(121)
tweets_split <- initial_split(tweets)
tweets_train <- training(tweets_split)
tweets_test <- testing(tweets_split)
tweets_fold <- vfold_cv(tweets_train, v = 10)
```

### Feature engineering

```{r}
library(textrecipes)
tweets_rec <- tweets_train %>% 
    recipe(retweet_count ~ like_count + quote_count + followers + content
           + username) %>% 
    step_log(all_numeric_predictors(), all_outcomes(), base = 10,
             offset = 1) %>% 
    step_other(username, threshold = 5) %>% 
    step_dummy(username, one_hot = TRUE) %>% 
    step_tokenize(content, token = "tweets") %>% 
    step_stopwords(content, stopword_source = "stopwords-iso") %>% 
    step_tokenfilter(content, max_tokens = tune()) %>% 
    step_tf(content)
    
```

### xgboost model

```{r}
tweets_mod_xg <- boost_tree(mtry = tune(),
                            trees = tune(),
                            min_n = tune(),
                            tree_depth = tune(),
                            learn_rate = tune(),
                            loss_reduction = tune(),
                            sample_size = tune()) %>% 
    set_engine("xgboost") %>% 
    set_mode("regression")
```

### xgboost workflow
```{r}
tweets_wf_xg <- workflow() %>% 
    add_recipe(tweets_rec) %>% 
    add_model(tweets_mod_xg)
```

### Tuning xgboost model with grid_latin_hypercube

```{r}
xg_grid <- grid_latin_hypercube(
    finalize(mtry(), tweets_train),
    trees(),
    min_n(),
    tree_depth(),
    learn_rate(),
    loss_reduction(),
    sample_size = sample_prop(),
    max_tokens(),
    size = 100
)
```

```{r}
set.seed(121)
tweets_xg_res <- tune_grid(
    tweets_wf_xg,
    resamples = tweets_fold,
    grid = xg_grid,
    control = control_grid(save_pred = TRUE,
                           save_workflow = TRUE)
)

autoplot(tweets_xg_res)
```

```{r}
show_best(tweets_xg_res, "rmse") %>% 
    relocate(.metric, mean)
final_xg <- finalize_workflow(
    tweets_wf_xg,
    select_best(tweets_xg_res, "rmse")
)
```

- The best rmse is 0.199 for the training set.

### Important variables
```{r}
library(vip)
final_xg %>% 
    fit(data = tweets_train) %>% 
    pull_workflow_fit() %>% 
    vip(geom = "col")
```

### Fitting on the test set

```{r}
final_res <- last_fit(final_xg, tweets_split)

final_res %>% 
    collect_metrics()
```

- The best rmse is 0.198 for the test set.

### How well did the model tuned by latin_hypercube do?

```{r}
collect_predictions(final_res) %>% 
    ggplot(aes(exp(retweet_count), exp(.pred))) +
    geom_point(alpha = 0.6, color = "midnightblue") +
    geom_abline(lty = 2, color = "red") +
    coord_obs_pred() +
    labs(x = "# of retweets (observed)",
         y = "# of retweet (predicted)")
```

### Tuning with crossing (regular_grid)

```{r}

tweets_xg_spec <- boost_tree(
                             mtry = tune(),
                             trees = tune(),
                             learn_rate = 0.01) %>% 
    set_engine("xgboost") %>% 
    set_mode("regression")

tweets_wf_xg <- workflow() %>% 
     add_recipe(tweets_rec) %>% 
     add_model(tweets_xg_spec)

set.seed(2021)
tweets_xg_rs_crossing <- tweets_wf_xg %>% 
     tune_grid(tweets_fold,
              grid = crossing(mtry = seq(10, 50, 10),
                              trees = seq(100, 1000, 100),
                              max_tokens = seq(10, 100, 10)),
              control = control_grid(
                                     save_pred = TRUE,
                                     save_workflow = TRUE))
autoplot(tweets_xg_rs_crossing)
```

### Explore results

```{r}
show_best(tweets_xg_rs_crossing, "rmse")
show_best(tweets_xg_rs_crossing, "rsq")
```

- The best rmse for training data tuned by crossing is 0.19.

```{r}
final_xg_crossing <- 
    finalize_workflow(tweets_wf_xg,
                      select_best(tweets_xg_rs_crossing, "rmse"))
```

### Fitting on test data

```{r}
final_res_crossing <- last_fit(final_xg_crossing, tweets_split)
final_res_crossing %>% 
    collect_metrics()
```

- The best rmse for testing data tuned by crossing is 0.201.

```{r}
final_xg_crossing %>% 
    fit(data = tweets_train) %>% 
    pull_workflow_fit() %>% 
    vip(geom = "col")
```


### How well did the model tuned by crossing do?

```{r}
collect_predictions(final_res_crossing) %>% 
    ggplot(aes(exp(retweet_count), exp(.pred))) +
    geom_point(alpha = 0.6, color = "midnightblue") +
    geom_abline(lty = 2, color = "red") +
    coord_obs_pred() +
    labs(x = "# of retweets (observed)",
         y = "# of retweet (predicted)")
```

